model_params:
  model: DeepSpeech
  input_dim: 161
  hidden_dim: 512
  dropout_rate: 0.2
  num_classes: 35

stages:
  state_params:
    main_metric: CER
    minimize_metric: True

  data_params:
    num_workers: 8
    batch_size: 15
    data_dir: data/wavs
    train_data: data/train_wav_files.csv
    valid_data: data/valid_wav_files.csv

  criterion_params:
    criterion: CTCLoss
    zero_infinity: True

  callbacks_params:
    loss:
      callback: CriterionCallback
      input_key: [targets, input_lengths, target_lengths]
      output_key: [log_probs]

    optim:
      callback: OptimizerCallback
      # accumulation_steps: 2
      grad_clip_params:
        func: clip_grad_norm_
        max_norm: 1

    saver:
      callback: CheckpointCallback

    early_stopping:
      callback: EarlyStoppingCallback
      patience: 3
      metric: loss
      minimize: True
    
    char_error_rate:
      callback: CharErrorRateCallback
      output_key: log_probs
      input_key: texts
    
    telegram_logger:
      callback: TelegramLogger
      log_on_stage_start: False
      log_on_loader_start: False
      metric_names:
        - loss
        - CER
    
  stage1:
    state_params:
      num_epochs: 30

    optimizer_params:
      optimizer: Adam
      lr: 0.001

  stage2:
    state_params:
      num_epochs: 10

    optimizer_params:
      optimizer: Adam
      lr: 0.0001